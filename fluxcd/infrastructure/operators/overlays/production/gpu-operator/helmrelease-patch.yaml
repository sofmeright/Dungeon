apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: gpu-operator
spec:
  values:
    # Prometheus scraping for operator
    operator:
      podAnnotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
    # Enable CDI as default mode
    cdi:
      enabled: true
      default: true

    # Node selector - only deploy GPU components to nodes with GPUs
    daemonsets:
      nodeSelector:
        nvidia.com/gpu.present: "true"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
        - key: node.cilium.io/agent-not-ready
          operator: Exists
          effect: NoSchedule
      # Use OnDelete update strategy to prevent automatic driver pod restarts
      # Driver pods will only update when manually deleted
      updateStrategy: OnDelete

    # Driver configuration for production
    # Using host-installed drivers - no containerized driver configuration needed
    driver:
      enabled: false

    # Toolkit node selector
    toolkit:
      nodeSelector:
        nvidia.com/gpu.present: "true"
      env:
        - name: CDI_ENABLED
          value: "true"
        - name: NVIDIA_CONTAINER_RUNTIME_MODE
          value: "cdi"

    # Device plugin with time-slicing configuration for GPU sharing
    # Profiles sized by GPU capability - more powerful = more slices
    devicePlugin:
      enabled: true
      nodeSelector:
        nvidia.com/gpu.present: "true"
      config:
        name: time-slicing-config
        default: any
        create: true
        data:
          # Default fallback
          any: |-
            version: v1
            flags:
              migStrategy: none
            sharing:
              timeSlicing:
                renameByDefault: false
                failRequestsGreaterThanOne: false
                resources:
                - name: nvidia.com/gpu
                  replicas: 16
          # GTX 980 Ti - 6GB Maxwell, base reference
          gtx-980-ti: |-
            version: v1
            flags:
              migStrategy: none
            sharing:
              timeSlicing:
                renameByDefault: false
                failRequestsGreaterThanOne: false
                resources:
                - name: nvidia.com/gpu
                  replicas: 16
          # RTX A2000 12GB - 1.4x base TFLOPS
          rtx-a2000: |-
            version: v1
            flags:
              migStrategy: none
            sharing:
              timeSlicing:
                renameByDefault: false
                failRequestsGreaterThanOne: false
                resources:
                - name: nvidia.com/gpu
                  replicas: 24
          # RTX 3080 Ti 12GB - 6x base TFLOPS
          rtx-3080-ti: |-
            version: v1
            flags:
              migStrategy: none
            sharing:
              timeSlicing:
                renameByDefault: false
                failRequestsGreaterThanOne: false
                resources:
                - name: nvidia.com/gpu
                  replicas: 96

    # DCGM exporter node selector
    dcgmExporter:
      nodeSelector:
        nvidia.com/gpu.present: "true"
      podAnnotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9400"

    # GPU Feature Discovery node selector
    gfd:
      nodeSelector:
        nvidia.com/gpu.present: "true"

    # Validator - disabled in production (CDI mode doesn't require validation)
    validator:
      enabled: false

    # Node status exporter
    nodeStatusExporter:
      enabled: true
