- CRITICAL RULES:
  - Prefer using flux to reconcile resources from source. We are GitOps native, we use kubectl commands to adjust state only when it is otherwise impossible!!!!!
  - When working with files in source control, make clean moves that dont create a headache of files!!!!
  - STAY ON TASK when following directions. NO BAND AID, NO FUCKING WORK AROUNDS. IF YOU THINK WE NEED TO GIVE UP or regroup and re-evaluate. ASK. DONT MAKE THE CALL ON YOUR OWN to find alternative solutions or FIND A SHORTCUT. I CAN FIND MY OWN WAYS TO BASTARDIZE THINGS I DONT NEED YOUR FUCKING HELP. I want things done exactly how I ask. If I am to be offered an alternative conversation should stop till I tell you if I agree/disagree with the alternative proposed.

- FluxCD Infrastructure Structure:
  - `fluxcd/infrastructure/controllers/base` should contain TEMPLATED infrastructure resources WITHOUT any environment-specific values including: no hardcoded namespaces, image tags, replicas, storage classes, LoadBalancer IPs, cluster-specific annotations (lbipam.cilium.io/*), domain names, URLs, etc.
  - `fluxcd/infrastructure/controllers/overlays/production` should contain ALL environment-specific infrastructure configurations and patches for the production cluster: LoadBalancer IPs, cluster-specific annotations, domain names, storage classes, etc.
  - `fluxcd/infrastructure/configs` should only provide secrets and configuration values
  - `fluxcd/infrastructure/namespaces` manages all Kubernetes namespaces - ALL namespaces MUST be deployed via this path only
  - Base should NEVER contain deployment-ready configs - only generic templates that overlays patch with real values
  - Always use overlays/production for actual deployment to the production cluster, never deploy from base

- Secret Management Strategy:
  - Critical infrastructure apps (vault, zitadel, etc.) use SOPS for secret management so they can run with local auth without dependencies during cluster issues
  - Most other applications use Vault External Secrets Operator to manage secrets from Vault at http://172.22.30.102:8200/ui/vault/secrets/operationtimecapsule/kv/list
  - Vault secret path structure in operationtimecapsule namespace:
    - `apps/<app-name>` - bundled comprehensive secrets specific to that application (e.g., apps/linkwarden)
    - `smtp/<service-name>` - SMTP-related secrets that may be shared between applications (e.g., smtp/ofcourseimvegan)
    - `smb/<share-name>` - SMB/storage secrets that may be shared between applications (e.g., smb/media-books-rw)
    - Shared paths (smtp/, smb/) are for secrets used by multiple applications, app-specific paths (apps/) are for single application use
- FluxCD App Structure:
  - `fluxcd/apps/base/<app>/` contains TEMPLATED Kubernetes resources WITHOUT any environment-specific values including: no hardcoded namespaces, image tags, replicas, storage classes, LoadBalancer IPs, cluster-specific annotations (lbipam.cilium.io/*), domain names, URLs, etc. These are reusable templates across environments.
  - `fluxcd/apps/overlays/production/<app>/` references the base (`../../../base/<app>`) and contains ALL environment-specific configurations via patches: namespace, image tags, replica counts, storage classes, LoadBalancer configurations, ingress configs, domain names, URLs, cluster-specific annotations, etc. for the production cluster.
  - Base should NEVER contain deployment-ready configs - only generic templates that overlays patch with real values. If you see cluster-specific IPs, domains, or annotations in base, they must be moved to overlay patches.
  - Other environments (staging, dev) can inherit the same base with different overlays.
  - Never deploy directly from base - always use overlays for actual deployments.
- Cluster initialization is handled by bash\_importing_from_sibling_repo\bootstrap-k8s-install-dependencies.sh bootstrap-k8s-initialize-control-plane.sh and a reset script. No other manipulation should be needed for initial cluster setup.

- Stateful sets should be used for PVCs that are for stateful applications! Deployments should only be used when the applications state doesnt need to be kept!

- Cluster Networking:
  - Pfsense router IPs are 172.22.144.21 & 172.22.144.23; the carp vip is 172.22.144.22. They provide BGP by peering with 172.22.144.150-154 172.22.144.170-74 and advertising routes for 172.22.30.0/24.
  - Cluster Pod CIDR 192.168.144.0/20
  - DNS CLuserIP 10.144.0.10
  - Node Network: 
    - dungeon-chest-001  172.22.144.170
    - dungeon-chest-002  172.22.144.171
    - dungeon-chest-003  172.22.144.172
    - dungeon-chest-004  172.22.144.173
    - dungeon-chest-005  172.22.144.174
    - dungeon-map-001    172.22.144.150
    - dungeon-map-002    172.22.144.151
    - dungeon-map-003    172.22.144.152
    - dungeon-map-004    172.22.144.153
    - dungeon-map-005    172.22.144.154
  - BGP LOAD BALANCERS:
    - General CIDR: 172.22.30.0/24.
    - Shared IPs:
      - Administrative (e.g. vault,weave,zitadel): 172.22.30.86 (sharing-key: administrative-services)
      - General MediaServers: 172.22.30.123 (sharing-key: media-servers)
      - DNS & NTP, similar publicly needed core services: 172.22.30.122 (sharing-key: core-services)
      - Monitoring: 172.22.30.137 (sharing-key: monitoring-services)
      - Tools w/o userdata (it-tools, podinfo, searxng): 172.22.30.107 (sharing-key: utility-tools)
      - Archival/Content Management (linkwarden, calibre-web, mealie): 172.22.30.222 (sharing-key: archival-content)